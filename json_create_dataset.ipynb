{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'workspace'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lade JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def json_read(data_path):\n",
    "    with open(data_path, 'r') as data:\n",
    "        data = json.load(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_NAME = '/instances_default.json'\n",
    "DATA_PATH = ANNOTATION_PATH+'/original'+ JSON_NAME\n",
    "data = json_read(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bennene Bilder im Verzeichnis images und in der Annotationsdatei um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_images(IMAGE_PATH):\n",
    "    index=1\n",
    "    img  = os.listdir(IMAGE_PATH)\n",
    "    for i in img:\n",
    "        new_name = f\"{index:012d}\"+'.jpeg'\n",
    "        old_path = os.path.join(IMAGE_PATH, i)\n",
    "        new_path = os.path.join(IMAGE_PATH, new_name)\n",
    "        os.rename(old_path, new_path)\n",
    "        index += 1\n",
    "\n",
    "def rename_images_in_annotation():\n",
    "    index=1\n",
    "    for img in data['images']:\n",
    "        new_name = f\"{index:012d}\"+'.jpeg'\n",
    "        img['file_name'] = new_name \n",
    "        index += 1\n",
    "\n",
    "rename_images(IMAGE_PATH+'/original')\n",
    "rename_images_in_annotation()\n",
    "\n",
    "with open(ANNOTATION_PATH+'/original' + JSON_NAME, 'w') as destination_file:\n",
    "    json.dump(data, destination_file, indent=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "bounding_boxes = []\n",
    "labels = []\n",
    "image_height = 1366\n",
    "image_width = 768\n",
    "\n",
    "for image in data['images']:\n",
    "    one_image = []\n",
    "    one_image.append(image['id'])\n",
    "    one_image.append(image['file_name'])\n",
    "    images.append(one_image)\n",
    "\n",
    "for annotation in data['annotations']:\n",
    "    one_box = []\n",
    "    box_and_id = []\n",
    "    one_box.append(annotation['bbox'])\n",
    "    bounding_boxes.append(one_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_imgaes(input_path, output_path, height, width):\n",
    "    image =  cv2.imread(input_path)\n",
    "    resized_image = cv2.resize(image, (height, width))\n",
    "    cv2.imwrite(output_path, resized_image)    \n",
    "\n",
    "def resize_bounding_boxes_and_area(input_path,bounding_boxes, height, width):\n",
    "    image =  cv2.imread(input_path)\n",
    "    height_ratio = height / image.shape[0]\n",
    "    width_ratio = width / image.shape[1]\n",
    "    \n",
    "    for box in bounding_boxes:\n",
    "        resized_boxes = []\n",
    "        resized_area = 0\n",
    "\n",
    "        x = np.round(box[0]*width_ratio,2)\n",
    "        y = np.round(box[1]*height_ratio,2)\n",
    "        x_width = np.round(box[2]*width_ratio,2)\n",
    "        y_height = np.round(box[3]*height_ratio,2)\n",
    "        resized_boxes.append([x, y, x_width, y_height])\n",
    "\n",
    "        resized_area = x_width * y_height\n",
    "\n",
    "    return x, y, x_width, y_height, resized_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "new_height = 224\n",
    "new_width = 224\n",
    "OUTPUT_PATH_IMAGES = IMAGE_PATH + '/' + str(new_height) + 'x' + str(new_width)\n",
    "OUTPUTPATH_ANNOTATIONS = ANNOTATION_PATH + '/' + str(new_height) + 'x' + str(new_width)\n",
    "\n",
    "os.makedirs(OUTPUT_PATH_IMAGES, exist_ok=True)\n",
    "os.makedirs(OUTPUTPATH_ANNOTATIONS, exist_ok=True)\n",
    "\n",
    "#Copy JSON Doc in new ANNOTATIONPATH\n",
    "with open(DATA_PATH, 'r') as source_file:\n",
    "    data = json.load(source_file)\n",
    "with open(OUTPUTPATH_ANNOTATIONS + JSON_NAME, 'w') as destination_file:\n",
    "    json.dump(data, destination_file, indent=2)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize Images\n",
    "for img in range(len(images)):\n",
    "    resize_imgaes(IMAGE_PATH+'/original'+ '/' +images[img][1], OUTPUT_PATH_IMAGES+ '/' +images[img][1], new_height, new_width)\n",
    "\n",
    "\n",
    "with open(OUTPUTPATH_ANNOTATIONS + JSON_NAME, 'r') as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "\n",
    "#Resize BBox and area\n",
    "for i, annotation in enumerate(data['annotations']):\n",
    "    calculate_resize = resize_bounding_boxes_and_area(IMAGE_PATH+'/original'+ '/' +images[0][1],bounding_boxes[i], new_height, new_width)\n",
    "    new_box = calculate_resize[0],calculate_resize[1],calculate_resize[2],calculate_resize[3]\n",
    "    new_area = calculate_resize[4]\n",
    "    annotation['bbox'] = new_box\n",
    "    annotation['area'] = new_area\n",
    "\n",
    "#Change height/width\n",
    "for image in data['images']:\n",
    "    image['height']=new_height\n",
    "    image['width']=new_width\n",
    "\n",
    "with open(OUTPUTPATH_ANNOTATIONS + JSON_NAME, 'w') as destination_file:\n",
    "    json.dump(data, destination_file, indent=2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation 697\n",
      "{'image_path': 'workspace/images/224x224/000000000001.jpeg', 'bbox': [11.48, 60.11, 151.89, 110.05], 'class_id': 1}\n",
      "workspace/images/224x224/000000000001.jpeg\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "images = data['images']\n",
    "annotations = data['annotations']\n",
    "categories = data['categories']\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for annotation in annotations:\n",
    "    image_info = next(image for image in images if image['id'] == annotation['image_id'])\n",
    "    image_path = OUTPUT_PATH_IMAGES + '/'+ image_info['file_name']\n",
    "    bbox = annotation['bbox']  # [x, y, width, height]\n",
    "    class_id = annotation['category_id']\n",
    "\n",
    "    xmin, ymin, width, height = bbox\n",
    "    xmax, ymax = xmin + width, ymin + height\n",
    "\n",
    "    dataset.append({\n",
    "        'image_path': image_path,\n",
    "        'bbox': [xmin, ymin, xmax, ymax],\n",
    "        'class_id': class_id\n",
    "    })\n",
    "\n",
    "print('Annotation',len(dataset))\n",
    "da =dataset[0]\n",
    "print(dataset[0])\n",
    "print(da['image_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_file_list(directory):\n",
    "    file_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        normalized_path = os.path.normpath(full_path)\n",
    "        normalized_path = normalized_path.replace(os.path.sep, '/')\n",
    "        if os.path.isfile(normalized_path):\n",
    "            file_list.append(normalized_path)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(697, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntestTargets = {\\n    \"class_label\": testLabels,\\n    \"bounding_box\": testBBoxes\\n}\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def convert_annotations_to_array(coco_data, num_classes=41):\n",
    "    annotations = coco_data['annotations']\n",
    "    num_annotations = len(annotations)\n",
    "\n",
    "    # Initialize empty arrays for bounding boxes and labels\n",
    "    bounding_boxes = np.zeros((num_annotations, 4), dtype=np.float32)\n",
    "    labels = np.zeros((num_annotations,), dtype=np.int32)\n",
    "\n",
    "    for i, annotation in enumerate(annotations):\n",
    "        # Extract bounding box coordinates\n",
    "        bbox = annotation['bbox']\n",
    "        bounding_boxes[i] = np.array([bbox[0], bbox[1], bbox[2], bbox[3]], dtype=np.float32)\n",
    "\n",
    "        # Extract class label\n",
    "        labels[i] = annotation['category_id']\n",
    "\n",
    "    return bounding_boxes, labels\n",
    "\n",
    "\n",
    "bounding_boxes, labels = convert_annotations_to_array(data)\n",
    "\n",
    "#bbox_data = np.random.random((41, bounding_boxes))\n",
    "\n",
    "trainTargets = {\n",
    "    \"class_label\": labels,\n",
    "    \"bounding_box\": bounding_boxes\n",
    "}\n",
    "print(bounding_boxes.shape)\n",
    "\"\"\"\n",
    "testTargets = {\n",
    "    \"class_label\": testLabels,\n",
    "    \"bounding_box\": testBBoxes\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 224, 224, 3)\n",
      "(17, 41, 4)\n",
      "(17, 41)\n"
     ]
    }
   ],
   "source": [
    "directory_path = OUTPUT_PATH_IMAGES\n",
    "files = get_file_list(directory_path)\n",
    "\n",
    "\n",
    "bbox_list=[]\n",
    "class_id_list=[]\n",
    "image_path_list=[]\n",
    "\n",
    "for k in files:\n",
    "    ann_bbox=[]\n",
    "    ann_class_id=[]\n",
    "    for i in dataset:\n",
    "        d = i\n",
    "        if d['image_path'] == k:\n",
    "            ann_bbox.append(d['bbox'])\n",
    "            #ann_bbox.append(d['class_id'])\n",
    "            ann_class_id.append(d['class_id'])\n",
    "    \n",
    "    image = cv2.imread(d['image_path'])\n",
    "    image = image / 255.0 \n",
    "\n",
    "        \n",
    "    bbox_list.append(ann_bbox)\n",
    "    class_id_list.append(ann_class_id)\n",
    "    image_path_list.append(image)\n",
    "\n",
    "images_data = np.array(image_path_list)\n",
    "bounding_boxes = np.array(bbox_list)\n",
    "class_labels = np.array(class_id_list)\n",
    "\n",
    "print(images_data.shape)\n",
    "print(bounding_boxes.shape)\n",
    "print(class_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "class_ids = []\n",
    "\n",
    "for cat in data['categories']:\n",
    "    class_name = cat['name']\n",
    "    class_ids.append(class_name)\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "print(len(class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.2\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 5\n",
    "GLOBAL_CLIPNORM = 10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "    \"yolo_v8_s_backbone_coco\"  # We will use yolov8 small backbone with coco weights\n",
    ")\n",
    "#Freeze base model\n",
    "#base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=len(class_mapping),\n",
    "    bounding_box_format=\"xywh\",\n",
    "    backbone=backbone,\n",
    "    fpn_depth=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yolov8_detector\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " model (Functional)          {'P3': (None, None, None,    5089760   ['input_2[0][0]']             \n",
      "                             128),                                                                \n",
      "                              'P4': (None, None, None,                                            \n",
      "                             256),                                                                \n",
      "                              'P5': (None, None, None,                                            \n",
      "                             512)}                                                                \n",
      "                                                                                                  \n",
      " tf.repeat (TFOpLambda)      (None, None, None, 512)      0         ['model[0][2]']               \n",
      "                                                                                                  \n",
      " tf.repeat_1 (TFOpLambda)    (None, None, None, 512)      0         ['tf.repeat[0][0]']           \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)    (None, None, None, 768)      0         ['tf.repeat_1[0][0]',         \n",
      "                                                                     'model[0][1]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_conv (Conv  (None, None, None, 256)      196608    ['tf.concat_5[0][0]']         \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_bn (BatchN  (None, None, None, 256)      1024      ['pa_fpn_p4p5_pre_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre (Activatio  (None, None, None, 256)      0         ['pa_fpn_p4p5_pre_bn[0][0]']  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " tf.split_4 (TFOpLambda)     [(None, None, None, 128),    0         ['pa_fpn_p4p5_pre[0][0]']     \n",
      "                              (None, None, None, 128)]                                            \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_1_pad (Z  (None, None, None, 128)      0         ['tf.split_4[0][1]']          \n",
      " eroPadding2D)                                                                                    \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_1_conv (  (None, None, None, 128)      147456    ['pa_fpn_p4p5_pre_0_1_pad[0][0\n",
      " Conv2D)                                                            ]']                           \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_1_bn (Ba  (None, None, None, 128)      512       ['pa_fpn_p4p5_pre_0_1_conv[0][\n",
      " tchNormalization)                                                  0]']                          \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_1 (Activ  (None, None, None, 128)      0         ['pa_fpn_p4p5_pre_0_1_bn[0][0]\n",
      " ation)                                                             ']                            \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_2_pad (Z  (None, None, None, 128)      0         ['pa_fpn_p4p5_pre_0_1[0][0]'] \n",
      " eroPadding2D)                                                                                    \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_2_conv (  (None, None, None, 128)      147456    ['pa_fpn_p4p5_pre_0_2_pad[0][0\n",
      " Conv2D)                                                            ]']                           \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_2_bn (Ba  (None, None, None, 128)      512       ['pa_fpn_p4p5_pre_0_2_conv[0][\n",
      " tchNormalization)                                                  0]']                          \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_pre_0_2 (Activ  (None, None, None, 128)      0         ['pa_fpn_p4p5_pre_0_2_bn[0][0]\n",
      " ation)                                                             ']                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)    (None, None, None, 384)      0         ['tf.split_4[0][0]',          \n",
      "                                                                     'tf.split_4[0][1]',          \n",
      "                                                                     'pa_fpn_p4p5_pre_0_2[0][0]'] \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_output_conv (C  (None, None, None, 256)      98304     ['tf.concat_6[0][0]']         \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_output_bn (Bat  (None, None, None, 256)      1024      ['pa_fpn_p4p5_output_conv[0][0\n",
      " chNormalization)                                                   ]']                           \n",
      "                                                                                                  \n",
      " pa_fpn_p4p5_output (Activa  (None, None, None, 256)      0         ['pa_fpn_p4p5_output_bn[0][0]'\n",
      " tion)                                                              ]                             \n",
      "                                                                                                  \n",
      " tf.repeat_2 (TFOpLambda)    (None, None, None, 256)      0         ['pa_fpn_p4p5_output[0][0]']  \n",
      "                                                                                                  \n",
      " tf.repeat_3 (TFOpLambda)    (None, None, None, 256)      0         ['tf.repeat_2[0][0]']         \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)    (None, None, None, 384)      0         ['tf.repeat_3[0][0]',         \n",
      "                                                                     'model[0][0]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_conv (Co  (None, None, None, 128)      49152     ['tf.concat_7[0][0]']         \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_bn (Batc  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_pre_conv[0][0]\n",
      " hNormalization)                                                    ']                            \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre (Activat  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_pre_bn[0][0]']\n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.split_5 (TFOpLambda)     [(None, None, None, 64),     0         ['pa_fpn_p3p4p5_pre[0][0]']   \n",
      "                              (None, None, None, 64)]                                             \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_1_pad   (None, None, None, 64)       0         ['tf.split_5[0][1]']          \n",
      " (ZeroPadding2D)                                                                                  \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_1_conv  (None, None, None, 64)       36864     ['pa_fpn_p3p4p5_pre_0_1_pad[0]\n",
      "  (Conv2D)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_1_bn (  (None, None, None, 64)       256       ['pa_fpn_p3p4p5_pre_0_1_conv[0\n",
      " BatchNormalization)                                                ][0]']                        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_1 (Act  (None, None, None, 64)       0         ['pa_fpn_p3p4p5_pre_0_1_bn[0][\n",
      " ivation)                                                           0]']                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_2_pad   (None, None, None, 64)       0         ['pa_fpn_p3p4p5_pre_0_1[0][0]'\n",
      " (ZeroPadding2D)                                                    ]                             \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_2_conv  (None, None, None, 64)       36864     ['pa_fpn_p3p4p5_pre_0_2_pad[0]\n",
      "  (Conv2D)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_2_bn (  (None, None, None, 64)       256       ['pa_fpn_p3p4p5_pre_0_2_conv[0\n",
      " BatchNormalization)                                                ][0]']                        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_pre_0_2 (Act  (None, None, None, 64)       0         ['pa_fpn_p3p4p5_pre_0_2_bn[0][\n",
      " ivation)                                                           0]']                          \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)    (None, None, None, 192)      0         ['tf.split_5[0][0]',          \n",
      "                                                                     'tf.split_5[0][1]',          \n",
      "                                                                     'pa_fpn_p3p4p5_pre_0_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_output_conv   (None, None, None, 128)      24576     ['tf.concat_8[0][0]']         \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_output_bn (B  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_output_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_output (Acti  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_output_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_output[0][0]']\n",
      " pad (ZeroPadding2D)                                                                              \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_pa\n",
      " conv (Conv2D)                                                      d[0][0]']                     \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_co\n",
      " bn (BatchNormalization)                                            nv[0][0]']                    \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1   (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bn\n",
      " (Activation)                                                       [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.concat_9 (TFOpLambda)    (None, None, None, 384)      0         ['pa_fpn_p3p4p5_downsample1[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'pa_fpn_p4p5_output[0][0]']  \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      98304     ['tf.concat_9[0][0]']         \n",
      " block_pre_conv (Conv2D)                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_bn (BatchNormali                                         ock_pre_conv[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre (Activation)                                             ock_pre_bn[0][0]']            \n",
      "                                                                                                  \n",
      " tf.split_6 (TFOpLambda)     [(None, None, None, 128),    0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      "                              (None, None, None, 128)]              ock_pre[0][0]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['tf.split_6[0][1]']          \n",
      " block_pre_0_1_pad (ZeroPad                                                                       \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_1_conv (Conv2D                                         ock_pre_0_1_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_1_bn (BatchNor                                         ock_pre_0_1_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_1 (Activation)                                         ock_pre_0_1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_2_pad (ZeroPad                                         ock_pre_0_1[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_2_conv (Conv2D                                         ock_pre_0_2_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_2_bn (BatchNor                                         ock_pre_0_2_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_0_2 (Activation)                                         ock_pre_0_2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_1_pad (ZeroPad                                         ock_pre_0_2[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_1_conv (Conv2D                                         ock_pre_1_1_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_1_bn (BatchNor                                         ock_pre_1_1_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_1 (Activation)                                         ock_pre_1_1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_2_pad (ZeroPad                                         ock_pre_1_1[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      147456    ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_2_conv (Conv2D                                         ock_pre_1_2_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      512       ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_2_bn (BatchNor                                         ock_pre_1_2_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_pre_1_2 (Activation)                                         ock_pre_1_2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_10 (TFOpLambda)   (None, None, None, 512)      0         ['tf.split_6[0][0]',          \n",
      "                                                                     'tf.split_6[0][1]',          \n",
      "                                                                     'pa_fpn_p3p4p5_downsample1_bl\n",
      "                                                                    ock_pre_0_2[0][0]',           \n",
      "                                                                     'pa_fpn_p3p4p5_downsample1_bl\n",
      "                                                                    ock_pre_1_2[0][0]']           \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      131072    ['tf.concat_10[0][0]']        \n",
      " block_output_conv (Conv2D)                                                                       \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_output_bn (BatchNorm                                         ock_output_conv[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample1_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " block_output (Activation)                                          ock_output_bn[0][0]']         \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " pad (ZeroPadding2D)                                                ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_pa\n",
      " conv (Conv2D)                                                      d[0][0]']                     \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_co\n",
      " bn (BatchNormalization)                                            nv[0][0]']                    \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2   (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bn\n",
      " (Activation)                                                       [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.concat_11 (TFOpLambda)   (None, None, None, 768)      0         ['pa_fpn_p3p4p5_downsample2[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'model[0][2]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      393216    ['tf.concat_11[0][0]']        \n",
      " block_pre_conv (Conv2D)                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      2048      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_bn (BatchNormali                                         ock_pre_conv[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre (Activation)                                             ock_pre_bn[0][0]']            \n",
      "                                                                                                  \n",
      " tf.split_7 (TFOpLambda)     [(None, None, None, 256),    0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      "                              (None, None, None, 256)]              ock_pre[0][0]']               \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['tf.split_7[0][1]']          \n",
      " block_pre_0_1_pad (ZeroPad                                                                       \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_1_conv (Conv2D                                         ock_pre_0_1_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_1_bn (BatchNor                                         ock_pre_0_1_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_1 (Activation)                                         ock_pre_0_1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_2_pad (ZeroPad                                         ock_pre_0_1[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_2_conv (Conv2D                                         ock_pre_0_2_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_2_bn (BatchNor                                         ock_pre_0_2_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_0_2 (Activation)                                         ock_pre_0_2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_1_pad (ZeroPad                                         ock_pre_0_2[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_1_conv (Conv2D                                         ock_pre_1_1_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_1_bn (BatchNor                                         ock_pre_1_1_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_1 (Activation)                                         ock_pre_1_1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_2_pad (ZeroPad                                         ock_pre_1_1[0][0]']           \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      589824    ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_2_conv (Conv2D                                         ock_pre_1_2_pad[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      1024      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_2_bn (BatchNor                                         ock_pre_1_2_conv[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_pre_1_2 (Activation)                                         ock_pre_1_2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " tf.concat_12 (TFOpLambda)   (None, None, None, 1024)     0         ['tf.split_7[0][0]',          \n",
      "                                                                     'tf.split_7[0][1]',          \n",
      "                                                                     'pa_fpn_p3p4p5_downsample2_bl\n",
      "                                                                    ock_pre_0_2[0][0]',           \n",
      "                                                                     'pa_fpn_p3p4p5_downsample2_bl\n",
      "                                                                    ock_pre_1_2[0][0]']           \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      524288    ['tf.concat_12[0][0]']        \n",
      " block_output_conv (Conv2D)                                                                       \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      2048      ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_output_bn (BatchNorm                                         ock_output_conv[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " pa_fpn_p3p4p5_downsample2_  (None, None, None, 512)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " block_output (Activation)                                          ock_output_bn[0][0]']         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_1_pad  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_output[0][0]']\n",
      "  (ZeroPadding2D)                                                                                 \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_1_pad  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      "  (ZeroPadding2D)                                                   ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_1_pad  (None, None, None, 512)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      "  (ZeroPadding2D)                                                   ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_1_pad (  (None, None, None, 128)      0         ['pa_fpn_p3p4p5_output[0][0]']\n",
      " ZeroPadding2D)                                                                                   \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_1_con  (None, None, None, 128)      147456    ['yolo_v8_head_1_class_1_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_1_pad (  (None, None, None, 256)      0         ['pa_fpn_p3p4p5_downsample1_bl\n",
      " ZeroPadding2D)                                                     ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_1_con  (None, None, None, 128)      294912    ['yolo_v8_head_2_class_1_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_1_pad (  (None, None, None, 512)      0         ['pa_fpn_p3p4p5_downsample2_bl\n",
      " ZeroPadding2D)                                                     ock_output[0][0]']            \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_1_con  (None, None, None, 128)      589824    ['yolo_v8_head_3_class_1_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_1_conv   (None, None, None, 64)       73728     ['yolo_v8_head_1_box_1_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_1_bn   (None, None, None, 128)      512       ['yolo_v8_head_1_class_1_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_1_conv   (None, None, None, 64)       147456    ['yolo_v8_head_2_box_1_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_1_bn   (None, None, None, 128)      512       ['yolo_v8_head_2_class_1_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_1_conv   (None, None, None, 64)       294912    ['yolo_v8_head_3_box_1_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_1_bn   (None, None, None, 128)      512       ['yolo_v8_head_3_class_1_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_1_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_1_box_1_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_1 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_1_class_1_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_1_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_2_box_1_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_1 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_2_class_1_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_1_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_3_box_1_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_1 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_3_class_1_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_1 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_1_box_1_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_2_pad  (None, None, None, 128)      0         ['yolo_v8_head_1_class_1[0][0]\n",
      "  (ZeroPadding2D)                                                   ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_1 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_2_box_1_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_2_pad  (None, None, None, 128)      0         ['yolo_v8_head_2_class_1[0][0]\n",
      "  (ZeroPadding2D)                                                   ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_1 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_3_box_1_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_2_pad  (None, None, None, 128)      0         ['yolo_v8_head_3_class_1[0][0]\n",
      "  (ZeroPadding2D)                                                   ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_2_pad (  (None, None, None, 64)       0         ['yolo_v8_head_1_box_1[0][0]']\n",
      " ZeroPadding2D)                                                                                   \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_2_con  (None, None, None, 128)      147456    ['yolo_v8_head_1_class_2_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_2_pad (  (None, None, None, 64)       0         ['yolo_v8_head_2_box_1[0][0]']\n",
      " ZeroPadding2D)                                                                                   \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_2_con  (None, None, None, 128)      147456    ['yolo_v8_head_2_class_2_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_2_pad (  (None, None, None, 64)       0         ['yolo_v8_head_3_box_1[0][0]']\n",
      " ZeroPadding2D)                                                                                   \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_2_con  (None, None, None, 128)      147456    ['yolo_v8_head_3_class_2_pad[0\n",
      " v (Conv2D)                                                         ][0]']                        \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_2_conv   (None, None, None, 64)       36864     ['yolo_v8_head_1_box_2_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_2_bn   (None, None, None, 128)      512       ['yolo_v8_head_1_class_2_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_2_conv   (None, None, None, 64)       36864     ['yolo_v8_head_2_box_2_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_2_bn   (None, None, None, 128)      512       ['yolo_v8_head_2_class_2_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_2_conv   (None, None, None, 64)       36864     ['yolo_v8_head_3_box_2_pad[0][\n",
      " (Conv2D)                                                           0]']                          \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_2_bn   (None, None, None, 128)      512       ['yolo_v8_head_3_class_2_conv[\n",
      " (BatchNormalization)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_2_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_1_box_2_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_2 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_1_class_2_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_2_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_2_box_2_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_2 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_2_class_2_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_2_bn (B  (None, None, None, 64)       256       ['yolo_v8_head_3_box_2_conv[0]\n",
      " atchNormalization)                                                 [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_2 (Ac  (None, None, None, 128)      0         ['yolo_v8_head_3_class_2_bn[0]\n",
      " tivation)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_2 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_1_box_2_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_class_3_con  (None, None, None, 42)       5418      ['yolo_v8_head_1_class_2[0][0]\n",
      " v (Conv2D)                                                         ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_2 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_2_box_2_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_class_3_con  (None, None, None, 42)       5418      ['yolo_v8_head_2_class_2[0][0]\n",
      " v (Conv2D)                                                         ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_2 (Acti  (None, None, None, 64)       0         ['yolo_v8_head_3_box_2_bn[0][0\n",
      " vation)                                                            ]']                           \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_class_3_con  (None, None, None, 42)       5418      ['yolo_v8_head_3_class_2[0][0]\n",
      " v (Conv2D)                                                         ']                            \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_box_3_conv   (None, None, None, 64)       4160      ['yolo_v8_head_1_box_2[0][0]']\n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_classifier   (None, None, None, 42)       0         ['yolo_v8_head_1_class_3_conv[\n",
      " (Activation)                                                       0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_box_3_conv   (None, None, None, 64)       4160      ['yolo_v8_head_2_box_2[0][0]']\n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_classifier   (None, None, None, 42)       0         ['yolo_v8_head_2_class_3_conv[\n",
      " (Activation)                                                       0][0]']                       \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_box_3_conv   (None, None, None, 64)       4160      ['yolo_v8_head_3_box_2[0][0]']\n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_classifier   (None, None, None, 42)       0         ['yolo_v8_head_3_class_3_conv[\n",
      " (Activation)                                                       0][0]']                       \n",
      "                                                                                                  \n",
      " tf.concat_13 (TFOpLambda)   (None, None, None, 106)      0         ['yolo_v8_head_1_box_3_conv[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'yolo_v8_head_1_classifier[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " tf.concat_14 (TFOpLambda)   (None, None, None, 106)      0         ['yolo_v8_head_2_box_3_conv[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'yolo_v8_head_2_classifier[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " tf.concat_15 (TFOpLambda)   (None, None, None, 106)      0         ['yolo_v8_head_3_box_3_conv[0]\n",
      "                                                                    [0]',                         \n",
      "                                                                     'yolo_v8_head_3_classifier[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " yolo_v8_head_1_output_resh  (None, None, 106)            0         ['tf.concat_13[0][0]']        \n",
      " ape (Reshape)                                                                                    \n",
      "                                                                                                  \n",
      " yolo_v8_head_2_output_resh  (None, None, 106)            0         ['tf.concat_14[0][0]']        \n",
      " ape (Reshape)                                                                                    \n",
      "                                                                                                  \n",
      " yolo_v8_head_3_output_resh  (None, None, 106)            0         ['tf.concat_15[0][0]']        \n",
      " ape (Reshape)                                                                                    \n",
      "                                                                                                  \n",
      " tf.concat_16 (TFOpLambda)   (None, None, 106)            0         ['yolo_v8_head_1_output_reshap\n",
      "                                                                    e[0][0]',                     \n",
      "                                                                     'yolo_v8_head_2_output_reshap\n",
      "                                                                    e[0][0]',                     \n",
      "                                                                     'yolo_v8_head_3_output_reshap\n",
      "                                                                    e[0][0]']                     \n",
      "                                                                                                  \n",
      " box_outputs (Activation)    (None, None, 106)            0         ['tf.concat_16[0][0]']        \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, None, 64)             0         ['box_outputs[0][0]']         \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, None, 42)             0         ['box_outputs[0][0]']         \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " box (Concatenate)           (None, None, 64)             0         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " class (Concatenate)         (None, None, 42)             0         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " non_max_suppression (NonMa  multiple                     0         []                            \n",
      " xSuppression)                                                                                    \n",
      "                                                                                                  \n",
      " yolov8_label_encoder (YOLO  multiple                     0         []                            \n",
      " V8LabelEncoder)                                                                                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12813342 (48.88 MB)\n",
      "Trainable params: 12791774 (48.80 MB)\n",
      "Non-trainable params: 21568 (84.25 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    global_clipnorm=GLOBAL_CLIPNORM,\n",
    ")\n",
    "\n",
    "yolo.compile(optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\")\n",
    "#yolo.compile(optimizer='adam', loss={'classes': 'categorical_crossentropy', 'boxes': 'mse'})\n",
    "yolo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5971 - box_loss: 0.2610 - class_loss: 0.3360WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.5971 - box_loss: 0.2610 - class_loss: 0.3360\n",
      "Epoch 2/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5993 - box_loss: 0.2678 - class_loss: 0.3315WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.5993 - box_loss: 0.2678 - class_loss: 0.3315\n",
      "Epoch 3/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5976 - box_loss: 0.2710 - class_loss: 0.3266WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.5976 - box_loss: 0.2710 - class_loss: 0.3266\n",
      "Epoch 4/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5867 - box_loss: 0.2686 - class_loss: 0.3182WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.5867 - box_loss: 0.2686 - class_loss: 0.3182\n",
      "Epoch 5/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5781 - box_loss: 0.2676 - class_loss: 0.3105WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.5781 - box_loss: 0.2676 - class_loss: 0.3105\n",
      "Epoch 6/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5769 - box_loss: 0.2718 - class_loss: 0.3051WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.5769 - box_loss: 0.2718 - class_loss: 0.3051\n",
      "Epoch 7/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5651 - box_loss: 0.2655 - class_loss: 0.2996WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.5651 - box_loss: 0.2655 - class_loss: 0.2996\n",
      "Epoch 8/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5657 - box_loss: 0.2723 - class_loss: 0.2934WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.5657 - box_loss: 0.2723 - class_loss: 0.2934\n",
      "Epoch 9/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5518 - box_loss: 0.2642 - class_loss: 0.2875WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.5518 - box_loss: 0.2642 - class_loss: 0.2875\n",
      "Epoch 10/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5460 - box_loss: 0.2648 - class_loss: 0.2812WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.5460 - box_loss: 0.2648 - class_loss: 0.2812\n",
      "Epoch 11/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5463 - box_loss: 0.2699 - class_loss: 0.2764WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 0.5463 - box_loss: 0.2699 - class_loss: 0.2764\n",
      "Epoch 12/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5353 - box_loss: 0.2632 - class_loss: 0.2721WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.5353 - box_loss: 0.2632 - class_loss: 0.2721\n",
      "Epoch 13/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5336 - box_loss: 0.2668 - class_loss: 0.2668WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 0.5336 - box_loss: 0.2668 - class_loss: 0.2668\n",
      "Epoch 14/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5213 - box_loss: 0.2613 - class_loss: 0.2600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.5213 - box_loss: 0.2613 - class_loss: 0.2600\n",
      "Epoch 15/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5204 - box_loss: 0.2651 - class_loss: 0.2553WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 0.5204 - box_loss: 0.2651 - class_loss: 0.2553\n",
      "Epoch 16/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5103 - box_loss: 0.2574 - class_loss: 0.2529WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.5103 - box_loss: 0.2574 - class_loss: 0.2529\n",
      "Epoch 17/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5058 - box_loss: 0.2590 - class_loss: 0.2467WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.5058 - box_loss: 0.2590 - class_loss: 0.2467\n",
      "Epoch 18/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5085 - box_loss: 0.2659 - class_loss: 0.2426WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.5085 - box_loss: 0.2659 - class_loss: 0.2426\n",
      "Epoch 19/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5004 - box_loss: 0.2604 - class_loss: 0.2400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.5004 - box_loss: 0.2604 - class_loss: 0.2400\n",
      "Epoch 20/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4989 - box_loss: 0.2630 - class_loss: 0.2358WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.4989 - box_loss: 0.2630 - class_loss: 0.2358\n",
      "Epoch 21/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4931 - box_loss: 0.2616 - class_loss: 0.2315WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.4931 - box_loss: 0.2616 - class_loss: 0.2315\n",
      "Epoch 22/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4804 - box_loss: 0.2554 - class_loss: 0.2250WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.4804 - box_loss: 0.2554 - class_loss: 0.2250\n",
      "Epoch 23/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4727 - box_loss: 0.2513 - class_loss: 0.2213WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.4727 - box_loss: 0.2513 - class_loss: 0.2213\n",
      "Epoch 24/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4754 - box_loss: 0.2576 - class_loss: 0.2178WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.4754 - box_loss: 0.2576 - class_loss: 0.2178\n",
      "Epoch 25/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4643 - box_loss: 0.2491 - class_loss: 0.2152WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 0.4643 - box_loss: 0.2491 - class_loss: 0.2152\n",
      "Epoch 26/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4688 - box_loss: 0.2577 - class_loss: 0.2111WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.4688 - box_loss: 0.2577 - class_loss: 0.2111\n",
      "Epoch 27/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4537 - box_loss: 0.2467 - class_loss: 0.2070WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.4537 - box_loss: 0.2467 - class_loss: 0.2070\n",
      "Epoch 28/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4605 - box_loss: 0.2569 - class_loss: 0.2036WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.4605 - box_loss: 0.2569 - class_loss: 0.2036\n",
      "Epoch 29/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4531 - box_loss: 0.2528 - class_loss: 0.2003WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.4531 - box_loss: 0.2528 - class_loss: 0.2003\n",
      "Epoch 30/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4553 - box_loss: 0.2583 - class_loss: 0.1970WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.4553 - box_loss: 0.2583 - class_loss: 0.1970\n",
      "Epoch 31/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4432 - box_loss: 0.2496 - class_loss: 0.1936WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.4432 - box_loss: 0.2496 - class_loss: 0.1936\n",
      "Epoch 32/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4499 - box_loss: 0.2592 - class_loss: 0.1907WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.4499 - box_loss: 0.2592 - class_loss: 0.1907\n",
      "Epoch 33/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4426 - box_loss: 0.2546 - class_loss: 0.1880WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.4426 - box_loss: 0.2546 - class_loss: 0.1880\n",
      "Epoch 34/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4481 - box_loss: 0.2621 - class_loss: 0.1860WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.4481 - box_loss: 0.2621 - class_loss: 0.1860\n",
      "Epoch 35/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4400 - box_loss: 0.2576 - class_loss: 0.1824WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.4400 - box_loss: 0.2576 - class_loss: 0.1824\n",
      "Epoch 36/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4255 - box_loss: 0.2472 - class_loss: 0.1783WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.4255 - box_loss: 0.2472 - class_loss: 0.1783\n",
      "Epoch 37/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4336 - box_loss: 0.2585 - class_loss: 0.1751WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 0.4336 - box_loss: 0.2585 - class_loss: 0.1751\n",
      "Epoch 38/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4224 - box_loss: 0.2503 - class_loss: 0.1720WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.4224 - box_loss: 0.2503 - class_loss: 0.1720\n",
      "Epoch 39/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4250 - box_loss: 0.2553 - class_loss: 0.1697WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.4250 - box_loss: 0.2553 - class_loss: 0.1697\n",
      "Epoch 40/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4220 - box_loss: 0.2547 - class_loss: 0.1674WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.4220 - box_loss: 0.2547 - class_loss: 0.1674\n",
      "Epoch 41/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4207 - box_loss: 0.2563 - class_loss: 0.1645WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.4207 - box_loss: 0.2563 - class_loss: 0.1645\n",
      "Epoch 42/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4197 - box_loss: 0.2574 - class_loss: 0.1623WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.4197 - box_loss: 0.2574 - class_loss: 0.1623\n",
      "Epoch 43/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4109 - box_loss: 0.2508 - class_loss: 0.1601WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.4109 - box_loss: 0.2508 - class_loss: 0.1601\n",
      "Epoch 44/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4170 - box_loss: 0.2594 - class_loss: 0.1576WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.4170 - box_loss: 0.2594 - class_loss: 0.1576\n",
      "Epoch 45/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4089 - box_loss: 0.2536 - class_loss: 0.1553WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.4089 - box_loss: 0.2536 - class_loss: 0.1553\n",
      "Epoch 46/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4133 - box_loss: 0.2604 - class_loss: 0.1529WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.4133 - box_loss: 0.2604 - class_loss: 0.1529\n",
      "Epoch 47/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4039 - box_loss: 0.2536 - class_loss: 0.1503WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.4039 - box_loss: 0.2536 - class_loss: 0.1503\n",
      "Epoch 48/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4011 - box_loss: 0.2535 - class_loss: 0.1476WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.4011 - box_loss: 0.2535 - class_loss: 0.1476\n",
      "Epoch 49/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3997 - box_loss: 0.2549 - class_loss: 0.1449WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.3997 - box_loss: 0.2549 - class_loss: 0.1449\n",
      "Epoch 50/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3982 - box_loss: 0.2551 - class_loss: 0.1431WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.3982 - box_loss: 0.2551 - class_loss: 0.1431\n",
      "Epoch 51/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3990 - box_loss: 0.2569 - class_loss: 0.1421WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.3990 - box_loss: 0.2569 - class_loss: 0.1421\n",
      "Epoch 52/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3941 - box_loss: 0.2555 - class_loss: 0.1386WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.3941 - box_loss: 0.2555 - class_loss: 0.1386\n",
      "Epoch 53/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3890 - box_loss: 0.2516 - class_loss: 0.1374WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.3890 - box_loss: 0.2516 - class_loss: 0.1374\n",
      "Epoch 54/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3995 - box_loss: 0.2636 - class_loss: 0.1359WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.3995 - box_loss: 0.2636 - class_loss: 0.1359\n",
      "Epoch 55/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3905 - box_loss: 0.2577 - class_loss: 0.1327WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.3905 - box_loss: 0.2577 - class_loss: 0.1327\n",
      "Epoch 56/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3883 - box_loss: 0.2584 - class_loss: 0.1299WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.3883 - box_loss: 0.2584 - class_loss: 0.1299\n",
      "Epoch 57/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3855 - box_loss: 0.2569 - class_loss: 0.1286WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.3855 - box_loss: 0.2569 - class_loss: 0.1286\n",
      "Epoch 58/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3926 - box_loss: 0.2656 - class_loss: 0.1270WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.3926 - box_loss: 0.2656 - class_loss: 0.1270\n",
      "Epoch 59/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3927 - box_loss: 0.2672 - class_loss: 0.1255WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.3927 - box_loss: 0.2672 - class_loss: 0.1255\n",
      "Epoch 60/60\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3863 - box_loss: 0.2626 - class_loss: 0.1237WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,box_loss,class_loss\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.3863 - box_loss: 0.2626 - class_loss: 0.1237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e4aac81f50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  \n",
    "                               patience=3,          \n",
    "                               restore_best_weights=True)  \n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "yolo.fit(\n",
    "    images_data, \n",
    "    {\"classes\": class_labels,\"boxes\": bounding_boxes},\n",
    "    epochs=60,\n",
    "    callbacks=early_stopping,\n",
    "    #callbacks=[EvaluateCOCOMetricsCallback(val_ds, \"model.h5\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "{'boxes': array([[[  96.93915  ,  132.06253  ,  190.81451  ,  207.33511  ],\n",
      "        [  48.796135 ,  135.99123  ,   89.20704  ,  138.59422  ],\n",
      "        [   9.963955 ,  131.27667  ,   78.30206  ,  138.25867  ],\n",
      "        [  33.774723 ,  137.17574  ,   87.57179  ,  138.06252  ],\n",
      "        [ 119.56271  ,  145.9644   ,  131.02914  ,  136.30507  ],\n",
      "        [ -10.205013 ,  135.30757  ,   77.01924  ,  143.17174  ],\n",
      "        [  57.594707 ,  144.79167  ,   99.12862  ,  137.33174  ],\n",
      "        [  19.857788 ,  137.6918   ,   84.773315 ,  138.00125  ],\n",
      "        [ 102.42645  ,  148.27646  ,  123.04248  ,  135.04178  ],\n",
      "        [ -49.36269  ,  139.9113   ,  109.52658  ,  135.01173  ],\n",
      "        [ -20.69986  ,  129.18628  ,  190.70314  ,  210.93924  ],\n",
      "        [ -10.557405 ,  111.20355  ,   80.35826  ,  140.11537  ],\n",
      "        [  73.28781  ,  136.73502  ,   97.47667  ,  137.04828  ],\n",
      "        [ -51.859535 ,  117.39769  ,  113.76164  ,  133.66429  ],\n",
      "        [ -14.36742  ,   87.7521   ,   84.05769  ,  138.07416  ],\n",
      "        [-213.63092  , -125.11957  ,  533.8248   ,  517.5216   ],\n",
      "        [   9.565456 ,  113.644    ,   66.731094 ,  139.63037  ],\n",
      "        [  22.330116 ,  123.69612  ,   93.46887  ,  135.34987  ],\n",
      "        [ -16.042725 ,   47.21791  ,   85.34057  ,  136.50044  ],\n",
      "        [ -24.46827  ,    8.421585 ,   93.95139  ,  132.33101  ],\n",
      "        [ 137.2427   ,  137.30353  ,  126.459656 ,  127.97586  ],\n",
      "        [ -52.810562 ,   94.168365 ,  114.936646 ,  132.31961  ],\n",
      "        [  48.709717 ,  121.19818  ,  201.27162  ,  218.18054  ],\n",
      "        [ -31.135155 ,   94.5152   ,  194.03311  ,  217.84076  ],\n",
      "        [  86.61801  ,  150.77188  ,  114.72179  ,  132.30707  ],\n",
      "        [  10.22382  ,   90.00807  ,   79.154724 ,  128.10234  ],\n",
      "        [ -53.39638  ,   72.08386  ,  115.243546 ,  130.2222   ],\n",
      "        [   6.853842 ,   49.842133 ,   68.475746 ,  136.01436  ],\n",
      "        [ -30.99033  ,  -14.130035 ,  101.09534  ,  129.55841  ],\n",
      "        [   7.789747 ,   75.338486 ,   67.032486 ,  135.30226  ],\n",
      "        [ -53.937355 ,   47.818634 ,  115.7884   ,  130.12453  ],\n",
      "        [   5.517521 ,   41.11463  ,   83.68437  ,  126.96395  ],\n",
      "        [  -1.2045517,   18.561172 ,   76.845634 ,  132.39772  ],\n",
      "        [ -53.680664 ,   10.264038 ,  115.68284  ,  127.22107  ],\n",
      "        [  -8.923933 ,   -6.061447 ,   85.18409  ,  129.95175  ],\n",
      "        [ -51.48362  ,   35.17415  ,  225.42911  ,  237.06456  ],\n",
      "        [  10.558868 ,  113.236626 ,   90.60136  ,  128.14429  ],\n",
      "        [  37.80753  ,  121.43613  ,   96.06232  ,  129.49588  ],\n",
      "        [   4.9741516,  108.96202  ,  198.43576  ,  216.34914  ],\n",
      "        [ -38.790894 ,    5.244522 ,  426.24945  ,  413.43445  ],\n",
      "        [  12.5870285,  142.87541  ,  237.0191   ,  252.12288  ],\n",
      "        [   7.4770584,  170.41354  ,  197.00674  ,  219.36044  ],\n",
      "        [  52.034233 ,  123.11081  ,  108.09594  ,  136.05649  ],\n",
      "        [ 114.724144 ,  136.29327  ,  117.92075  ,  129.68631  ],\n",
      "        [ -19.558533 ,   68.45444  ,  335.54428  ,  335.93237  ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ],\n",
      "        [  -1.       ,   -1.       ,   -1.       ,   -1.       ]]],\n",
      "      dtype=float32), 'confidence': array([[ 0.44037277,  0.40316486,  0.38636532,  0.37286654,  0.36384788,\n",
      "         0.3578291 ,  0.3546168 ,  0.34756556,  0.31302404,  0.2949059 ,\n",
      "         0.2924991 ,  0.29208964,  0.28262794,  0.27496898,  0.26644573,\n",
      "         0.2644392 ,  0.26355702,  0.2572701 ,  0.25449604,  0.25369182,\n",
      "         0.25073034,  0.2492903 ,  0.24091788,  0.24013893,  0.23905557,\n",
      "         0.23537159,  0.23481429,  0.23091015,  0.23083682,  0.22919336,\n",
      "         0.22898686,  0.22520238,  0.2242464 ,  0.21672519,  0.21456368,\n",
      "         0.21431774,  0.21165143,  0.21079609,  0.2101818 ,  0.20937951,\n",
      "         0.2066574 ,  0.20618404,  0.20534521,  0.2045097 ,  0.20254572,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "        -1.        , -1.        , -1.        , -1.        , -1.        ]],\n",
      "      dtype=float32), 'classes': array([[28, 21, 15, 21, 20, 20, 21, 20, 20, 20, 25, 20, 21, 20, 20, 29,\n",
      "        20, 20, 20, 20, 18, 20, 28, 25, 20, 20, 20, 20, 20, 19, 20, 20,\n",
      "        20, 20, 20, 27, 20, 20, 18, 38, 38, 19, 20, 18, 38, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1]], dtype=int64), 'num_detections': array([45])}\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image as keras_image\n",
    "\n",
    "img = OUTPUT_PATH_IMAGES + '/000000000001.jpeg'\n",
    "img = keras_image.load_img(img, target_size=(new_height, new_width))\n",
    "img_array = keras_image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0\n",
    "\n",
    "print(yolo.predict(img_array))\n",
    "boxes,confidence,classes,num_detections=yolo.predict(img_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Top Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras_cv.models.MobileNetV3Backbone.from_preset(\n",
    "    \"mobilenet_v3_large_imagenet\",\n",
    "    load_weights=False,\n",
    ")\n",
    "#Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 224, 224, 3)\n",
      "(17, 41, 4)\n",
      "(17, 41)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/mean_squared_error/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\Tristan\\AppData\\Local\\Temp\\ipykernel_27040\\601627433.py\", line 21, in <module>\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 543, in minimize\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 276, in compute_gradients\n\nIncompatible shapes: [13,4] vs. [13,41,4]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_50816]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tristan\\studium\\Semester7\\BBArchComparison\\json_create_dataset.ipynb Cell 29\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tristan/studium/Semester7/BBArchComparison/json_create_dataset.ipynb#X40sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(bounding_boxes\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tristan/studium/Semester7/BBArchComparison/json_create_dataset.ipynb#X40sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(class_labels\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tristan/studium/Semester7/BBArchComparison/json_create_dataset.ipynb#X40sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(images_data,  {\u001b[39m\"\u001b[39;49m\u001b[39mclass_id\u001b[39;49m\u001b[39m\"\u001b[39;49m: class_labels,\u001b[39m\"\u001b[39;49m\u001b[39mbbox\u001b[39;49m\u001b[39m\"\u001b[39;49m: bounding_boxes}, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tristan/studium/Semester7/BBArchComparison/json_create_dataset.ipynb#X40sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/mean_squared_error/BroadcastGradientArgs defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\Tristan\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\Tristan\\AppData\\Local\\Temp\\ipykernel_27040\\601627433.py\", line 21, in <module>\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 543, in minimize\n\n  File \"c:\\Users\\Tristan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 276, in compute_gradients\n\nIncompatible shapes: [13,4] vs. [13,41,4]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_50816]"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "inputs = keras.Input(shape=(new_height, new_width, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "class_id_output = keras.layers.Dense(41, activation='softmax', name='class_id')(x)\n",
    "\n",
    "bbox_output = keras.layers.Dense(4, name='bbox')(x)\n",
    "model = keras.Model(inputs, [class_id_output, bbox_output]) \n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss={'class_id': 'sparse_categorical_crossentropy', 'bbox': 'mean_squared_error'},#Regression für bbox\n",
    "    metrics={'class_id': 'accuracy'}\n",
    ")\n",
    "print(images_data.shape)\n",
    "print(bounding_boxes.shape)\n",
    "print(class_labels.shape)\n",
    "\n",
    "model.fit(images_data,  {\"class_id\": class_labels,\"bbox\": bounding_boxes}, epochs=20, validation_split=0.2)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "arr= [0.44037277,  0.40316486,  0.38636532,  0.37286654,  0.36384788,\n",
    "         0.3578291 ,  0.3546168 ,  0.34756556,  0.31302404,  0.2949059 ,\n",
    "         0.2924991 ,  0.29208964,  0.28262794,  0.27496898,  0.26644573,\n",
    "         0.2644392 ,  0.26355702,  0.2572701 ,  0.25449604,  0.25369182,\n",
    "         0.25073034,  0.2492903 ,  0.24091788,  0.24013893,  0.23905557,\n",
    "         0.23537159,  0.23481429,  0.23091015,  0.23083682,  0.22919336,\n",
    "         0.22898686,  0.22520238,  0.2242464 ,  0.21672519,  0.21456368,\n",
    "         0.21431774,  0.21165143,  0.21079609,  0.2101818 ,  0.20937951,\n",
    "         0.2066574 ,  0.20618404,  0.20534521,  0.2045097 ,  0.20254572]\n",
    "print(len(arr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
